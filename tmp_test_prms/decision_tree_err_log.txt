Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/06/08 15:23:13 WARN Utils: Your hostname, host0 resolves to a loopback address: 127.0.1.1; using 172.27.154.144 instead (on interface wlp9s0)
17/06/08 15:23:13 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
17/06/08 15:23:14 INFO SparkContext: Running Spark version 2.1.0
17/06/08 15:23:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/06/08 15:23:14 INFO SecurityManager: Changing view acls to: host0
17/06/08 15:23:14 INFO SecurityManager: Changing modify acls to: host0
17/06/08 15:23:14 INFO SecurityManager: Changing view acls groups to: 
17/06/08 15:23:14 INFO SecurityManager: Changing modify acls groups to: 
17/06/08 15:23:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(host0); groups with view permissions: Set(); users  with modify permissions: Set(host0); groups with modify permissions: Set()
17/06/08 15:23:14 INFO Utils: Successfully started service 'sparkDriver' on port 45655.
17/06/08 15:23:14 INFO SparkEnv: Registering MapOutputTracker
17/06/08 15:23:14 INFO SparkEnv: Registering BlockManagerMaster
17/06/08 15:23:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/06/08 15:23:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/06/08 15:23:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-841487f2-b254-48d6-a059-bb462df5851c
17/06/08 15:23:14 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/06/08 15:23:14 INFO SparkEnv: Registering OutputCommitCoordinator
17/06/08 15:23:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/06/08 15:23:14 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.27.154.144:4040
17/06/08 15:23:14 INFO SparkContext: Added file file:/home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/ml_moduel/td_decision_tree_regression_prediction_interval_log_sinh.py at file:/home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/ml_moduel/td_decision_tree_regression_prediction_interval_log_sinh.py with timestamp 1496960594756
17/06/08 15:23:14 INFO Utils: Copying /home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/ml_moduel/td_decision_tree_regression_prediction_interval_log_sinh.py to /tmp/spark-680f71ef-7ec0-4b12-9452-4a3e6e21a445/userFiles-080fbbab-84b4-4cb4-ba8c-d058d8a4ff2c/td_decision_tree_regression_prediction_interval_log_sinh.py
17/06/08 15:23:14 INFO Executor: Starting executor ID driver on host localhost
17/06/08 15:23:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43412.
17/06/08 15:23:14 INFO NettyBlockTransferService: Server created on 172.27.154.144:43412
17/06/08 15:23:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/06/08 15:23:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.27.154.144, 43412, None)
17/06/08 15:23:14 INFO BlockManagerMasterEndpoint: Registering block manager 172.27.154.144:43412 with 366.3 MB RAM, BlockManagerId(driver, 172.27.154.144, 43412, None)
17/06/08 15:23:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.27.154.144, 43412, None)
17/06/08 15:23:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.27.154.144, 43412, None)
17/06/08 15:23:14 INFO SharedState: Warehouse path is 'file:/home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/spark-warehouse/'.
17/06/08 15:23:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 127.1 KB, free 366.2 MB)
17/06/08 15:23:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 14.3 KB, free 366.2 MB)
17/06/08 15:23:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.27.154.144:43412 (size: 14.3 KB, free: 366.3 MB)
17/06/08 15:23:15 INFO SparkContext: Created broadcast 0 from textFile at MLUtils.scala:99
17/06/08 15:23:15 INFO FileInputFormat: Total input paths to process : 1
17/06/08 15:23:15 INFO SparkContext: Starting job: reduce at MLUtils.scala:92
17/06/08 15:23:15 INFO DAGScheduler: Got job 0 (reduce at MLUtils.scala:92) with 8 output partitions
17/06/08 15:23:15 INFO DAGScheduler: Final stage: ResultStage 0 (reduce at MLUtils.scala:92)
17/06/08 15:23:15 INFO DAGScheduler: Parents of final stage: List()
17/06/08 15:23:15 INFO DAGScheduler: Missing parents: List()
17/06/08 15:23:15 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90), which has no missing parents
17/06/08 15:23:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 366.2 MB)
17/06/08 15:23:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 366.2 MB)
17/06/08 15:23:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.27.154.144:43412 (size: 2.3 KB, free: 366.3 MB)
17/06/08 15:23:15 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/06/08 15:23:15 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at MLUtils.scala:90)
17/06/08 15:23:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 8 tasks
17/06/08 15:23:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6190 bytes)
17/06/08 15:23:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 6190 bytes)
17/06/08 15:23:15 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 6190 bytes)
17/06/08 15:23:15 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 6190 bytes)
17/06/08 15:23:15 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 6190 bytes)
17/06/08 15:23:15 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 6190 bytes)
17/06/08 15:23:15 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 6190 bytes)
17/06/08 15:23:15 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 6190 bytes)
17/06/08 15:23:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/06/08 15:23:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/06/08 15:23:15 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/06/08 15:23:15 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/06/08 15:23:15 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/06/08 15:23:15 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
17/06/08 15:23:15 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
17/06/08 15:23:15 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
17/06/08 15:23:15 INFO Executor: Fetching file:/home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/ml_moduel/td_decision_tree_regression_prediction_interval_log_sinh.py with timestamp 1496960594756
17/06/08 15:23:15 INFO Utils: /home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/ml_moduel/td_decision_tree_regression_prediction_interval_log_sinh.py has been previously copied to /tmp/spark-680f71ef-7ec0-4b12-9452-4a3e6e21a445/userFiles-080fbbab-84b4-4cb4-ba8c-d058d8a4ff2c/td_decision_tree_regression_prediction_interval_log_sinh.py
17/06/08 15:23:15 INFO HadoopRDD: Input split: file:/home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/delta_error_train.libsvm:34492+17246
17/06/08 15:23:15 INFO HadoopRDD: Input split: file:/home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/delta_error_train.libsvm:120722+17250
17/06/08 15:23:15 INFO HadoopRDD: Input split: file:/home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/delta_error_train.libsvm:68984+17246
17/06/08 15:23:15 INFO HadoopRDD: Input split: file:/home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/delta_error_train.libsvm:86230+17246
17/06/08 15:23:15 INFO HadoopRDD: Input split: file:/home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/delta_error_train.libsvm:51738+17246
17/06/08 15:23:15 INFO HadoopRDD: Input split: file:/home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/delta_error_train.libsvm:0+17246
17/06/08 15:23:15 INFO HadoopRDD: Input split: file:/home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/delta_error_train.libsvm:17246+17246
17/06/08 15:23:15 INFO HadoopRDD: Input split: file:/home/host0/Desktop/machine_learning_prms_accuracy/tmp_test_prms/delta_error_train.libsvm:103476+17246
17/06/08 15:23:15 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/06/08 15:23:15 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/06/08 15:23:15 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/06/08 15:23:15 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/06/08 15:23:15 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/06/08 15:23:15 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/06/08 15:23:15 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/06/08 15:23:15 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/06/08 15:23:15 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/06/08 15:23:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1201 bytes result sent to driver
17/06/08 15:23:15 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1201 bytes result sent to driver
17/06/08 15:23:15 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 1201 bytes result sent to driver
17/06/08 15:23:15 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1201 bytes result sent to driver
17/06/08 15:23:15 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1201 bytes result sent to driver
17/06/08 15:23:15 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1201 bytes result sent to driver
17/06/08 15:23:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1201 bytes result sent to driver
17/06/08 15:23:15 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1201 bytes result sent to driver
17/06/08 15:23:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 151 ms on localhost (executor driver) (1/8)
17/06/08 15:23:15 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 130 ms on localhost (executor driver) (2/8)
17/06/08 15:23:15 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 132 ms on localhost (executor driver) (3/8)
17/06/08 15:23:15 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 136 ms on localhost (executor driver) (4/8)
17/06/08 15:23:15 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 136 ms on localhost (executor driver) (5/8)
17/06/08 15:23:15 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 142 ms on localhost (executor driver) (6/8)
17/06/08 15:23:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 143 ms on localhost (executor driver) (7/8)
17/06/08 15:23:15 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 140 ms on localhost (executor driver) (8/8)
17/06/08 15:23:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/06/08 15:23:15 INFO DAGScheduler: ResultStage 0 (reduce at MLUtils.scala:92) finished in 0.166 s
17/06/08 15:23:15 INFO DAGScheduler: Job 0 finished: reduce at MLUtils.scala:92, took 0.221407 s
17/06/08 15:23:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.27.154.144:43412 in memory (size: 2.3 KB, free: 366.3 MB)
17/06/08 15:23:16 INFO SparkContext: Invoking stop() from shutdown hook
17/06/08 15:23:16 INFO SparkUI: Stopped Spark web UI at http://172.27.154.144:4040
17/06/08 15:23:16 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/06/08 15:23:16 INFO MemoryStore: MemoryStore cleared
17/06/08 15:23:16 INFO BlockManager: BlockManager stopped
17/06/08 15:23:16 INFO BlockManagerMaster: BlockManagerMaster stopped
17/06/08 15:23:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/06/08 15:23:16 INFO SparkContext: Successfully stopped SparkContext
17/06/08 15:23:16 INFO ShutdownHookManager: Shutdown hook called
17/06/08 15:23:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-680f71ef-7ec0-4b12-9452-4a3e6e21a445
17/06/08 15:23:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-680f71ef-7ec0-4b12-9452-4a3e6e21a445/pyspark-4cb37a34-702f-49cc-a4ad-4bff95e2c566
